{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 13:02:15.283681: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import neurokit2 as nk\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential  # En modelltyp i Keras som gör det enkelt att skapa lager av neurala nätverk sekventiellt\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout,MaxPooling1D,GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI = pd.read_csv(\"/Users/adinastark/Desktop/Heart disease/ptbdb/ptbdb_abnormal.csv\") \n",
    "HC = pd.read_csv(\"/Users/adinastark/Desktop/Heart disease/ptbdb/ptbdb_normal.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_name = ['label']  #skapar kolumn namn för abnormal data\n",
    "for num in range(MI.shape[1]-1):\n",
    "    tem = 'dim' + str(num)\n",
    "    new_column_name.append(tem)\n",
    "MI.columns = new_column_name    \n",
    "\n",
    "\n",
    "column_name = ['label'] #skapar koloumn namn for normal data\n",
    "for num in range(HC.shape[1]-1):\n",
    "    tem = 'dim' + str(num)\n",
    "    column_name.append(tem)\n",
    "HC.columns = column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separera data i tränings- och testuppsättningar\n",
    "train_MI = MI.iloc[0:6500]  # De första 6500 från abnormal för träning\n",
    "test_MI = MI.iloc[6500:9000]  # De sista 2500 från abnormal för testning\n",
    "train_HC = HC.iloc[0:2500]  # De första 2500 från normal för träning\n",
    "test_HC = HC.iloc[2500:3500]  # Rader 2500 till 3500 från normal för testning\n",
    "\n",
    "# Kombinera abnormal och normal data\n",
    "train = pd.concat([train_MI, train_HC], sort=True)\n",
    "test = pd.concat([test_MI, test_HC], sort=True)\n",
    "\n",
    "# Skapa ytrain och ytest baserat på labels\n",
    "ytrain = [1 if i < 6500 else 0 for i in range(9000)]  # 1 = abnormal, 0 = normal\n",
    "ytest = [1 if i < 2500 else 0 for i in range(3500)]   # 1 = abnormal, 0 = normal\n",
    "\n",
    "# Konvertera etiketter till one-hot encoding\n",
    "ytrain = to_categorical(ytrain)\n",
    "ytest = to_categorical(ytest)\n",
    "#to_categorical: Omvandlar etiketter från numeriska värden till one-hot representation:\n",
    "# 1 (abnormal) -> [0, 1]\n",
    "# 0 (normal) -> [1, 0]\n",
    "# Detta krävs eftersom CNN-modellen använder en softmax-utgång, vilket kräver etiketter i one-hot format.\n",
    "\n",
    "# Separera signaler från etiketter\n",
    "Xtrain = train.drop(columns=['label']).values  # Signaldata för träning\n",
    "Xtest = test.drop(columns=['label']).values  # Signaldata för testning\n",
    "\n",
    "# Lägg till brus i Xtrain\n",
    "def add_noise(data, noise_level=0.01):\n",
    "    noise = noise_level * np.random.normal(size=data.shape)\n",
    "    return data + noise\n",
    "\n",
    "\n",
    "# Skapa brusad data och kombinera\n",
    "Xtrain_noisy = add_noise(Xtrain)\n",
    "Xtrain = np.concatenate([Xtrain, Xtrain_noisy], axis=0)  # Kombinera original och brusad data\n",
    "ytrain = np.concatenate([ytrain, ytrain], axis=0)  # Fördubblar etiketterna för brusad data\n",
    "\n",
    "\n",
    "# Kontrollera att antal prover matchar\n",
    "print(f\"Xtrain shape: {Xtrain.shape}, ytrain shape: {ytrain.shape}\")\n",
    "print(f\"Xtest shape: {Xtest.shape}, ytest shape: {ytest.shape}\")\n",
    "\n",
    "# Omforma data för Conv1D\n",
    "Xtrain = Xtrain.reshape(len(Xtrain), 187, 1)  # 187 tidssteg, 1 kanal\n",
    "Xtest = Xtest.reshape(len(Xtest), 187, 1)\n",
    "\n",
    "# Normalisera data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "Xtrain = scaler.fit_transform(Xtrain.reshape(-1, 187)).reshape(-1, 187, 1)\n",
    "Xtest = scaler.transform(Xtest.reshape(-1, 187)).reshape(-1, 187, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=np.asarray(train)\n",
    "train=train.reshape(9000, 188, 1) #188 tidsteg (188 dimensioner) , 1 kanal (1-dim EKG))\n",
    "\n",
    "test=np.asarray(test)\n",
    "test=test.reshape(3500, 188, 1)\n",
    "# For conv1d statement: \n",
    "#input_shape = (ncols, 1) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(100, 5, activation='relu', input_shape=(188,1))) #100 filter, filterstorlek= 5 (små , lokala mönster), relu = aktiveringsfunktion\n",
    "model.add(Convolution1D(100, 10, activation='relu')) #filterstorlek 10, tar in bredare sammanhang\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Convolution1D(100, 10, activation='relu'))\n",
    "model.add(Convolution1D(160, 10, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.5)) #Slumpar bort 50% av anslutningarna för att minska överanpassning.\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu')) # Ett dense lager med 100 neuroner och ReLU\n",
    "model.add(Dense(2, activation='softmax')) #Utgångslager med 2 neuroner för att representera de två klasserna (normal och abnormal)\n",
    "#print(model_m.summary())\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005),  # Lägre learning rate\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Konvulution lager: extraherar mönster från EKG singal. Mindre filterstorlek -> mindre mönster\n",
    "# Poolinglager : Reducerar data för att minska beräkningskomplexiteten och generalisera mönstren\n",
    "#Dense lager: Slutför processen genom att klassificera signalen baserat på de extraherade funktionerna\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True) #stoppar innan de blir overfitting\n",
    "\n",
    "history = model.fit(\n",
    "    Xtrain, ytrain,  # Använd Xtrain för signaldata\n",
    "    validation_data=(Xtest, ytest),  # Använd Xtest för valideringssignaler\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,accuracy = model.evaluate(test, ytest, verbose=0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utvärdera modellen\n",
    "test_loss, test_accuracy = model.evaluate(Xtest, ytest)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Visualisera träningshistorik med ljusrosa och röd färg för accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', color='#ffb6c1')  # Ljusrosa för träning\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')  # Röd för validering\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')  # Standardfärg\n",
    "plt.xlabel('Epochs')         # Standardfärg\n",
    "plt.ylabel('Accuracy')       # Standardfärg\n",
    "plt.show()\n",
    "\n",
    "# Visualisera träningshistorik med ljusrosa och röd färg för loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='#ffb6c1')  # Ljusrosa för träning\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')  # Röd för validering\n",
    "plt.legend()\n",
    "plt.title('Model Loss')  # Standardfärg\n",
    "plt.xlabel('Epochs')     # Standardfärg\n",
    "plt.ylabel('Loss')       # Standardfärg\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gör prediktioner på valideringsdatan\n",
    "y_pred = model.predict(Xtest) #använder alla atribut i xtest för att predicta en ny y_pred\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Konvertera prediktioner till klassindex\n",
    "y_true = np.argmax(ytest, axis=1)  # Konvertera one-hot till klassindex\n",
    "\n",
    "#Y_pred: predictar utifrån Xtest\n",
    "#Y_true: Facit på predictade\n",
    "\n",
    "# Skapar en rapport\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=[\"Normal\", \"Abnormal\"]))\n",
    "\n",
    "# Skapa en confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "# Rosa\n",
    "cmap = sns.light_palette(\"pink\", as_cmap=True)\n",
    "\n",
    "#Plotta matris\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=cmap, xticklabels=[\"Normal\", \"Abnormal\"], yticklabels=[\"Normal\", \"Abnormal\"], cbar=False)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()\n",
    "\n",
    "# Utvärdera modellen på testdatan\n",
    "test_loss, test_accuracy = model.evaluate(Xtest, ytest)\n",
    "\n",
    "# Skriv ut resultaten\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generera sannolikheter för klassen 'abnormal'\n",
    "y_pred_probs = model.predict(Xtest)[:, 1]  # Hämta sannolikheter för klassen 'abnormal'\n",
    "\n",
    "# Beräkna ROC-kurvan\n",
    "fpr, tpr, thresholds = roc_curve(ytest.argmax(axis=1), y_pred_probs)\n",
    "\n",
    "# Beräkna AUC (Area Under the Curve)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotta ROC-kurvan\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='#ff69b4', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')  # Ljusrosa kurva\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)  # Diagonal linje för slumpmässig gissning\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ECG data from your CSV file\n",
    "ecg_df = pd.read_csv('/Users/adinastark/Desktop/Heart disease/ECG singal från klockan/ECG Signal 5- 20210609143423.csv', header=None)\n",
    "\n",
    "# Extract sampling rate from row 8, second column (e.g., \"499.348 Hz\")\n",
    "sampling_rate_str = ecg_df.iloc[8, 1]  # Adjust if sampling rate is stored differently\n",
    "sampling_rate = float(sampling_rate_str.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Function to resample ECG signal to 187 data points\n",
    "def resample_signal(signal, target_length=187):\n",
    "    x_original = np.linspace(0, 1, len(signal))\n",
    "    x_resampled = np.linspace(0, 1, target_length)\n",
    "    interpolator = interp1d(x_original, signal, kind='linear')\n",
    "    return interpolator(x_resampled)\n",
    "\n",
    "# Function to preprocess all RR intervals (between consecutive R-peaks)\n",
    "def preprocess_ecg_for_prediction(ecg_values, rpeaks, target_length=187):\n",
    "    resized_segments = []\n",
    "    \n",
    "    # Iterate through all consecutive R-peaks\n",
    "    for i in range(len(rpeaks['ECG_R_Peaks']) - 1):\n",
    "        start = rpeaks['ECG_R_Peaks'][i]\n",
    "        end = rpeaks['ECG_R_Peaks'][i + 1]\n",
    "        \n",
    "        # Extract segment between R-peaks\n",
    "        segment = ecg_values[start:end]\n",
    "        \n",
    "        # Resize the segment to 187 data points\n",
    "        resized_segment = resample_signal(segment, target_length)\n",
    "        \n",
    "        # Append the resized segment to the list\n",
    "        resized_segments.append(resized_segment)\n",
    "    \n",
    "    return np.array(resized_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess ECG signal for prediction\n",
    "X_input = preprocess_ecg_for_prediction(ecg_values, rpeaks)\n",
    "\n",
    "\n",
    "\n",
    "X_input_reshaped = X_input.reshape(len(X_input), -1)  # Omforma till 2D (n_samples, 187)\n",
    "X_input_normalized = scaler.transform(X_input_reshaped)  # Normalisera\n",
    "X_input_normalized = np.clip(X_input_normalized, 0, 1)  # Begränsar värden till intervallet [0, 1]\n",
    "X_input_normalized = X_input_normalized.reshape(len(X_input), 187, 1)  # Omforma tillbaka till 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = X_input.reshape(len(X_input), 187, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(predicted_classes)  # Output will be an array of class labels (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_ones = (np.sum(predicted_classes == 1) / len(predicted_classes)) * 100\n",
    "\n",
    "print(f\"Risk-percentage of abnormality: {percentage_ones:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
